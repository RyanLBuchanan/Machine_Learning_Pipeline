{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Pipeline: Wrapping up for Deployment\n",
    "\n",
    "\n",
    "In the previous notebooks, we worked through the typical Machine Learning pipeline steps to build a regression model that allows us to predict house prices. Briefly, we transformed variables in the dataset to make them suitable for use in a Regression model, then we selected the most predictive variables and finally we trained our model.\n",
    "\n",
    "Now, we want to deploy our model. We want to create an API, which we can call with new data, with new characteristics about houses, to get an estimate of the SalePrice. In order to do so, we need to write code in a very specific way. We will show you how to write production code in the next sections.\n",
    "\n",
    "Here, we will summarise the key pieces of code, that we need to take forward for this particular project, to put our model in production.\n",
    "\n",
    "Let's go ahead and get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the seed\n",
    "\n",
    "It is important to note, that we are engineering variables and pre-processing data with the idea of deploying the model. Therefore, from now on, for each step that includes some element of randomness, it is extremely important that we **set the seed**. This way, we can obtain reproducibility between our research and our development code.\n",
    "\n",
    "This is perhaps one of the most important lessons that you need to take away from this course: **Always set the seeds**.\n",
    "\n",
    "Let's go ahead and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "# to persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We need the training data to train our model in the production environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('houseprice.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data,\n",
    "    data['SalePrice'],\n",
    "    test_size=0.1,\n",
    "    # we are setting the seed here\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load selected features\n",
    "features = pd.read_csv('selected_features.csv')\n",
    "\n",
    "# Added the extra feature, LotFrontage\n",
    "features = features['0'].to_list() + ['LotFrontage']\n",
    "\n",
    "print('Number of features: ', len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineer missing values\n",
    "\n",
    "### Categorical variables\n",
    "\n",
    "For categorical variables, we will replace missing values with the string \"missing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the categorical variables that contain missing values\n",
    "\n",
    "vars_with_na = [\n",
    "    var for var in features\n",
    "    if X_train[var].isnull().sum() > 0 and X_train[var].dtypes == 'O'\n",
    "]\n",
    "\n",
    "# display categorical variables that we will engineer:\n",
    "vars_with_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have much less categorical variables with missing values than in our original dataset. But we still use categorical variables with NA for the final model, so we need to include this piece of feature engineering logic in the deployment pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I bring forward the code used in the feature engineering notebook:\n",
    "# (step 2)\n",
    "\n",
    "X_train[vars_with_na] = X_train[vars_with_na].fillna('Missing')\n",
    "X_test[vars_with_na] = X_test[vars_with_na].fillna('Missing')\n",
    "\n",
    "# check that we have no missing information in the engineered variables\n",
    "X_train[vars_with_na].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables\n",
    "\n",
    "To engineer missing values in numerical variables, we will:\n",
    "\n",
    "- add a binary missing value indicator variable\n",
    "- and then replace the missing values in the original variable with the mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the numerical variables that contain missing values:\n",
    "\n",
    "vars_with_na = [\n",
    "    var for var in features\n",
    "    if X_train[var].isnull().sum() > 0 and X_train[var].dtypes != 'O'\n",
    "]\n",
    "\n",
    "# display numerical variables with NA\n",
    "vars_with_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I bring forward the code used in the feature engineering notebook\n",
    "# with minor adjustments (step 2):\n",
    "\n",
    "var = 'LotFrontage'\n",
    "\n",
    "# calculate the mode\n",
    "mode_val = X_train[var].mode()[0]\n",
    "print('mode of LotFrontage: {}'.format(mode_val))\n",
    "\n",
    "# replace missing values by the mode\n",
    "# (in train and test)\n",
    "X_train[var] = X_train[var].fillna(mode_val)\n",
    "X_test[var] = X_test[var].fillna(mode_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal variables\n",
    "\n",
    "One of our temporal variables was selected to be used in the final model: 'YearRemodAdd'\n",
    "\n",
    "So we need to deploy the bit of code that creates it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the temporal var \"elapsed years\"\n",
    "\n",
    "# I bring this bit of code forward from the notebook on feature\n",
    "# engineering (step 2)\n",
    "\n",
    "def elapsed_years(df, var):\n",
    "    # capture difference between year variable\n",
    "    # and year in which the house was sold\n",
    "    \n",
    "    df[var] = df['YrSold'] - df[var]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = elapsed_years(X_train, 'YearRemodAdd')\n",
    "X_test = elapsed_years(X_test, 'YearRemodAdd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variable transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we apply the logarithmic function to the variables that\n",
    "# were selected (and the target):\n",
    "\n",
    "for var in ['LotFrontage', '1stFlrSF', 'GrLivArea', 'SalePrice']:\n",
    "    X_train[var] = np.log(X_train[var])\n",
    "    X_test[var] = np.log(X_test[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variables\n",
    "\n",
    "### Group rare labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's capture the categorical variables first\n",
    "\n",
    "cat_vars = [var for var in features if X_train[var].dtype == 'O']\n",
    "\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bringing thise from the notebook on feature engineering (step 2):\n",
    "\n",
    "def find_frequent_labels(df, var, rare_perc):\n",
    "    \n",
    "    # function finds the labels that are shared by more than\n",
    "    # a certain % of the houses in the dataset\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    tmp = df.groupby(var)['SalePrice'].count() / len(df)\n",
    "\n",
    "    return tmp[tmp > rare_perc].index\n",
    "\n",
    "\n",
    "for var in cat_vars:\n",
    "    \n",
    "    # find the frequent categories\n",
    "    frequent_ls = find_frequent_labels(X_train, var, 0.01)\n",
    "    print(var)\n",
    "    print(frequent_ls)\n",
    "    print()\n",
    "    \n",
    "    # replace rare categories by the string \"Rare\"\n",
    "    X_train[var] = np.where(X_train[var].isin(\n",
    "        frequent_ls), X_train[var], 'Rare')\n",
    "    \n",
    "    X_test[var] = np.where(X_test[var].isin(\n",
    "        frequent_ls), X_test[var], 'Rare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding of categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will assign discrete values to the strings of the variables,\n",
    "# so that the smaller value corresponds to the category that shows the smaller\n",
    "# mean house sale price\n",
    "\n",
    "\n",
    "def replace_categories(train, test, var, target):\n",
    "\n",
    "    # order the categories in a variable from that with the lowest\n",
    "    # house sale price, to that with the highest\n",
    "    ordered_labels = train.groupby([var])[target].mean().sort_values().index\n",
    "\n",
    "    # create a dictionary of ordered categories to integer values\n",
    "    ordinal_label = {k: i for i, k in enumerate(ordered_labels, 0)}\n",
    "\n",
    "    # use the dictionary to replace the categorical strings by integers\n",
    "    train[var] = train[var].map(ordinal_label)\n",
    "    test[var] = test[var].map(ordinal_label)\n",
    "    \n",
    "    print(var)\n",
    "    print(ordinal_label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in cat_vars:\n",
    "    replace_categories(X_train, X_test, var, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check absence of na\n",
    "[var for var in features if X_train[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check absence of na\n",
    "[var for var in features if X_test[var].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "For use in linear models, features need to be either scaled or normalised. In the next section, I will scale features between the min and max values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture the target\n",
    "y_train = X_train['SalePrice']\n",
    "y_test = X_test['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# train scaler\n",
    "scaler.fit(X_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore maximum values of variables\n",
    "scaler.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore minimum values of variables\n",
    "scaler.data_min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the train and test set, and add on the Id and SalePrice variables\n",
    "X_train = scaler.transform(X_train[features])\n",
    "X_test = scaler.transform(X_test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Linear Regression: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "# remember to set the random_state / seed\n",
    "\n",
    "lin_model = Lasso(alpha=0.005, random_state=0)\n",
    "\n",
    "# train the model\n",
    "lin_model.fit(X_train, y_train)\n",
    "\n",
    "# we persist the model for future use\n",
    "joblib.dump(lin_model, 'lasso_regression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model:\n",
    "# ====================\n",
    "\n",
    "# remember that we log transformed the output (SalePrice)\n",
    "# in our feature engineering notebook (step 2).\n",
    "\n",
    "# In order to get the true performance of the Lasso\n",
    "# we need to transform both the target and the predictions\n",
    "# back to the original house prices values.\n",
    "\n",
    "# We will evaluate performance using the mean squared error and\n",
    "# the root of the mean squared error and r2\n",
    "\n",
    "# make predictions for train set\n",
    "pred = lin_model.predict(X_train)\n",
    "\n",
    "# determine mse and rmse\n",
    "print('train mse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_train), np.exp(pred)))))\n",
    "print('train rmse: {}'.format(int(\n",
    "    sqrt(mean_squared_error(np.exp(y_train), np.exp(pred))))))\n",
    "print('train r2: {}'.format(\n",
    "    r2_score(np.exp(y_train), np.exp(pred))))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "pred = lin_model.predict(X_test)\n",
    "\n",
    "# determine mse and rmse\n",
    "print('test mse: {}'.format(int(\n",
    "    mean_squared_error(np.exp(y_test), np.exp(pred)))))\n",
    "print('test rmse: {}'.format(int(\n",
    "    sqrt(mean_squared_error(np.exp(y_test), np.exp(pred))))))\n",
    "print('test r2: {}'.format(\n",
    "    r2_score(np.exp(y_test), np.exp(pred))))\n",
    "print()\n",
    "\n",
    "print('Average house price: ', int(np.exp(y_train).median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all for this notebook. And that is all for this section too.\n",
    "\n",
    "**In the next section, we will show you how to productionise this code for model deployment**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
